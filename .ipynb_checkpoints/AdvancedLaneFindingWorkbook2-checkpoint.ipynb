{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the notebook on load\n",
    "Borrowed from http://stackoverflow.com/a/38856870/3222727\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<script>\n",
    "    // AUTORUN ALL CELLS ON NOTEBOOK-LOAD!\n",
    "    require(\n",
    "        ['base/js/namespace', 'jquery'], \n",
    "        function(jupyter, $) {\n",
    "            $(jupyter.events).on(\"kernel_ready.Kernel\", function () {\n",
    "                console.log(\"Auto-running all cells-below...\");\n",
    "                jupyter.actions.call('jupyter-notebook:run-all-cells-below');\n",
    "                jupyter.actions.call('jupyter-notebook:save-notebook');\n",
    "            });\n",
    "        }\n",
    "    );\n",
    "</script>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the Plotter Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.plotter_util as pltu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.gridspec as gridspec\n",
    "import sys\n",
    "from moviepy.editor import VideoFileClip\n",
    "from optparse import OptionParser\n",
    "\n",
    "# images = glob.glob('camera_cal/calibration*.jpg')\n",
    "from src2.lane_finder import LaneFinder\n",
    "\n",
    "\n",
    "chessboard_cols = 9\n",
    "chessboard_rows = 6\n",
    "img_size = (720, 1280)\n",
    "calibration_data_dir = 'camera_cal'\n",
    "input_video='project_video.mp4'\n",
    "output_video='output_video2.mp4'\n",
    "finder = LaneFinder(calibration_data_dir, chessboard_cols, chessboard_rows, (1280, 720))\n",
    "\n",
    "input_clip = VideoFileClip(input_video)\n",
    "annotated_clip = input_clip.fl_image(finder.find_lane_in_img)\n",
    "annotated_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate the Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Camera calibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.camera_calibrator as ccb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the chessboard corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx=9\n",
    "ny=6\n",
    "\n",
    "img = cv2.imread('./camera_cal/calibration2.jpg')\n",
    "copied_img = img.copy() # to be useful in plotting as the image will be changed by the below function\n",
    "img_corners = ccb.find_and_draw_chessboard_corner_for_image(img, nx=nx, ny=ny)\n",
    "pltu.plot_compare_two_images(copied_img, img_corners, \n",
    "                             suptitle='Detect corners in a chessboard', \n",
    "                             subtitle1='Input chess board image', subtitle2='Detected corners',\n",
    "                            is_save=True, save_path=\"./output_images/chessboard_corners1.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Corners for All Images - Get image and object points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_file_pattern='./camera_cal/calibration*.jpg'\n",
    "objpoints, imgpoints, img_size = ccb.find_chessboard_corners(img_file_pattern, nx=nx, ny=ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera matrix and distortion coefficients\n",
    "To calibrate a camera, we use multiple chessboard images, and compute camera matrix and distortion coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtx, dist = ccb.calibrate_camera(img_file_pattern,nx=nx,  ny=ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undistort the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./camera_cal/calibration2.jpg')\n",
    "undist_image = cv2.undistort(img, mtx, dist, None, mtx) # OR we can use ccb.undistort_image(image, mtx, dist)\n",
    "\n",
    "pltu.plot_compare_two_images(image, undist_image, \n",
    "                             suptitle='Undistort the Image', \n",
    "                             subtitle1='Original', subtitle2='Undistorted',\n",
    "                            is_save=True, save_path=\"./output_images/chessboard_undistort.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with the Test Images i.e. Lane Image data now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undistort the Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('./test_images/test1.jpg')\n",
    "undist_image = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "pltu.plot_compare_two_images(img, undist_image, \n",
    "                             suptitle='Undistort the Image', \n",
    "                             subtitle1='Original', subtitle2='Undistorted',\n",
    "                            is_save=True, save_path=\"./output_images/chessboard_undistort.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warp the Image - Perspective Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Import the perspective_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.perspective_transformer as ppt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checked Warped Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check warped image\n",
    "img = cv2.imread('./camera_cal/calibration3.jpg')\n",
    "warped, M, Minv = ppt.corners_unwarp(img, mtx, dist, nx=9, ny=6)\n",
    "pltu.plot_compare_two_images(image, warped, \n",
    "                             suptitle='UnWarp the Image', \n",
    "                             subtitle1='Original', subtitle2='Warped',\n",
    "                            is_save=True, save_path=\"./output_images/chessboard_unwarped.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding - Color and Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobel Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Sobel Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.sobel_thresholder as sbt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Sobel Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample image\n",
    "image = cv2.imread('./test_images/test1.jpg')\n",
    "sobel_x_binary = sbt.abs_sobel_threshold(image, orient='x', sobel_kernel=15, thres=(15, 100))\n",
    "sobel_y_binary = sbt.abs_sobel_threshold(image, orient='y', sobel_kernel=15, thres=(15, 100))\n",
    "\n",
    "pltu.plot_compare_three_images(image, sobel_x_binary, sobel_y_binary,\n",
    "                             suptitle='Applying the sobel filter', \n",
    "                             subtitle1='Original', subtitle2='Sobel_x', subtitle3='Sobel_y',\n",
    "                            is_save=True, save_path=\"./output_images/abs_sobel.png\", gray_vector=[False, False, True])\n",
    "\n",
    "# pltu.plot_compare_three_images_from_n(image, sobel_x_binary, sobel_y_binary,\n",
    "#                              suptitle='Applying the sobel filter', \n",
    "#                              subtitle1='Original', subtitle2='Sobel_x', subtitle3='Sobel_y',\n",
    "#                             is_save=True, save_path=\"./output_images/abs_sobel.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitude of the Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample image\n",
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "mag_binary = sbt.mag_threshold(img, sobel_kernel=15, thres=(15, 100))\n",
    "\n",
    "pltu.plot_compare_two_images(img, mag_binary, \n",
    "                             suptitle='Magnituide of gradient filter', \n",
    "                             subtitle1='Original', subtitle2='Applied Magintude Gradient',\n",
    "                            is_save=True, save_path=\"./output_images/magnitude_threshold.png\",\n",
    "                             gray_vector=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direction of the Gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample image\n",
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "dir_mask = sbt.dir_threshold(img, sobel_kernel=15, thres=(0.7, 1.1))\n",
    "\n",
    "pltu.plot_compare_two_images(img, mag_binary, \n",
    "                             suptitle='Direction of the Gradient', \n",
    "                             subtitle1='Original', subtitle2='Applied Directional Gradient',\n",
    "                            is_save=True, save_path=\"./output_images/direction_threshold.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine gradient filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('./test_images/test1.jpg')\n",
    "combined = sbt.apply_gradient_filters(img, sobel_kernel=15, abs_thres=(20,100), \n",
    "                                                 mag_thres=(30, 100), dir_thres=(0.7, 1.3))\n",
    "\n",
    "pltu.plot_compare_two_images(img, mag_binary, \n",
    "                             suptitle='Combine gradient filters', \n",
    "                             subtitle1='Original', subtitle2='Applied Sobel Combined Gradient',\n",
    "                            is_save=True, save_path=\"./output_images/combined_sobel.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Color Thresholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.color_thresholder as cth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HLS Color Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "channel='HLS'\n",
    "h_channel, l_channel, s_channel  = cth.split_channels(img, channel)\n",
    "\n",
    "# Plotting now\n",
    "images = [img, h_channel, l_channel, s_channel]\n",
    "subtitles = ['Original', 'h_channel', 'l_channel', 's_channel']\n",
    "pltu.plot_compare_n_images_grayed( images, suptitle=channel, \n",
    "                             subtitles=subtitles,grayed_array=[False, True, True, True],\n",
    "                            is_save=True, save_path='./output_images/'+channel+'_demo.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSV color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "channel='HSV'\n",
    "h_channel, s_channel, v_channel  = cth.split_channels(img, channel)\n",
    "\n",
    "# Plotting now\n",
    "images = [img, h_channel, s_channel, v_channel]\n",
    "subtitles = ['Original', 'h_channel', 's_channel', 'v_channel']\n",
    "pltu.plot_compare_n_images_grayed( images, suptitle=channel, \n",
    "                             subtitles=subtitles,grayed_array=[False, True, True, True],\n",
    "                            is_save=True, save_path='./output_images/'+channel+'_demo.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YCrCb color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "channel='YCrCb'\n",
    "y_channel, cr_channel, cb_channel  = cth.split_channels(img, channel)\n",
    "\n",
    "# Plotting now\n",
    "images = [img, y_channel, cr_channel, cb_channel]\n",
    "subtitles = ['Original', 'y_channel', 'cr_channel', 'cb_channel']\n",
    "pltu.plot_compare_n_images_grayed( images, suptitle=channel, \n",
    "                             subtitles=subtitles,grayed_array=[False, True, True, True],\n",
    "                            is_save=True, save_path='./output_images/'+channel+'_demo.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YUV color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "channel='YUV'\n",
    "y_channel, u_channel, v_channel  = cth.split_channels(img, channel)\n",
    "\n",
    "# Plotting now\n",
    "images =            [img, y_channel, u_channel, v_channel]\n",
    "subtitles = ['Original', 'y_channel', 'u_channel', 'v_channel']\n",
    "pltu.plot_compare_n_images_grayed( images, suptitle=channel, \n",
    "                             subtitles=subtitles,grayed_array=[False, True, True, True],\n",
    "                            is_save=True, save_path='./output_images/'+channel+'_demo.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LUV color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "channel='LUV'\n",
    "l_channel, u_channel, v_channel  = cth.split_channels(img, channel)\n",
    "\n",
    "# Plotting now\n",
    "images = [img, l_channel, u_channel, v_channel]\n",
    "subtitles = ['Original', 'l_channel', 'u_channel', 'v_channel']\n",
    "pltu.plot_compare_n_images_grayed( images, suptitle=channel, \n",
    "                             subtitles=subtitles,grayed_array=[False, True, True, True],\n",
    "                            is_save=True, save_path='./output_images/'+channel+'_demo.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thresholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the final thresholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.final_thresholder as fth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Color Thresholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show example\n",
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "color_binary, combined_binary = fth.grad_color_threshold(img)\n",
    "\n",
    "\n",
    "images = [img, color_binary, combined_binary]\n",
    "subtitles = ['Original', 'Green: Gradient filter, Blue: Color filter', 'Total Filter']\n",
    "grayed = [False, True, True]\n",
    "\n",
    "pltu.plot_compare_n_images_grayed( images, suptitle=channel, \n",
    "                             subtitles=subtitles,grayed_array=grayed,\n",
    "                            is_save=True, save_path='./output_images/combined_filters_demo.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Perspective Transfomation - Finding Corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show example\n",
    "img = mpimg.imread('./test_images/test1.jpg')\n",
    "_, combined_binary = fth.grad_color_threshold(img)\n",
    "plt.imshow(combined_binary, cmap='gray')\n",
    "plotted = plt.plot([255, 600, 700, 1150], [719, 450, 450, 719], 'r-')\n",
    "plt.title('Finding source corners')\n",
    "plt.savefig('./output_images/src_corners.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Running the Perspective Transform on the Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_corners = [\n",
    "    [600, 450],  # top left\n",
    "    [700, 450],  # top right\n",
    "    [1150, 719], # bottom right\n",
    "    [255, 719]   # bottom left\n",
    "]\n",
    "\n",
    "offset=(300, 0)\n",
    "\n",
    "binary_warped, Minv = ppt.transform_with_offset(combined_binary.astype(np.uint8), src_corners, offset=offset, is_gray=False)\n",
    "\n",
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "pltu.plot_compare_two_images(img, binary_warped, \n",
    "                             suptitle='Normal Image and Bird Eye View', \n",
    "                             subtitle1='Original', subtitle2='Bird View',\n",
    "                             is_save=True, save_path=\"./output_images/warped.png\", gray_vector=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Image Thresholder and Transformer as 1 package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.image_thresholder_transformer as itt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "binary_warped, _, _ = itt.undistort_threshold_transform_image1(img, mtx, dist, corners)\n",
    "pltu.plot_compare_two_images(img, binary_warped, \n",
    "                             suptitle='Transforming and Thresholding', \n",
    "                             subtitle1='Original', subtitle2='Transformed and Thresholded',\n",
    "                             is_save=True, save_path=\"./output_images/full_transform.png\", gray_vector=[False, True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Histogram to identify lanes and Fit Polynomial to Sliding Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Lane Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.lane_detector as ldt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Lane Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_fitx, right_fitx, ploty, left_fit, right_fit = ldt.find_lane_lines(binary_warped, visualize=True)\n",
    "plt.savefig('./output_images/sliding_windows1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show sample curvature\n",
    "ldt.get_curvature_radius(left_fitx, right_fitx, ploty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring off center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(ldt.dist_from_center2(img, left_fit, right_fit))\n",
    "print(ldt.dist_from_center(left_fitx, right_fitx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize detected lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show example\n",
    "img = mpimg.imread('./test_images/test1.jpg')\n",
    "colored_binary, combined_binary = fth.grad_color_threshold(img)\n",
    "\n",
    "corners = [\n",
    "    [600, 450],  # top left\n",
    "    [700, 450],  # top right\n",
    "    [1150, 719], # bottom right\n",
    "    [255, 719]   # bottom left\n",
    "]\n",
    "\n",
    "dst = [[350,0],   [930,0],  [350,720],[930,720]]\n",
    "\n",
    "binary_warped, Minv = ppt.transform_with_offset(combined_binary.astype(np.uint8), corners, is_gray=False)\n",
    "result = ldt.show_inside_lane(img, binary_warped, Minv, left_fitx, right_fitx, ploty)\n",
    "\n",
    "pltu.plot_compare_two_images(img, result, \n",
    "                             suptitle='Visualize detected lane', \n",
    "                             subtitle1='Original', subtitle2='Visualize detected lane',\n",
    "                             is_save=True, save_path=\"./output_images/Visualize_detected_lane.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Import the pipline for 1 Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.final_pipeline as fnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "corners = [\n",
    "        [600, 450],  # top left\n",
    "        [700, 450],  # top right\n",
    "        [1150, 719], # bottom right\n",
    "        [255, 719]   # bottom left\n",
    "    ]\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "result = fnp.pipeline_for_image(img, mtx, dist, corners)\n",
    "\n",
    "plt.imshow(result)\n",
    "# plt.savefig('./output_images/pipeline_result.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.video_annotator as sva\n",
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "corners = [\n",
    "        [600, 450],  # top left\n",
    "        [700, 450],  # top right\n",
    "        [1150, 719], # bottom right\n",
    "        [255, 719]   # bottom left\n",
    "    ]\n",
    "\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "result = sva.plot_image(img, mtx, dist, corners)\n",
    "\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "corners = [\n",
    "        [600, 450],  # top left\n",
    "        [700, 450],  # top right\n",
    "        [1150, 719], # bottom right\n",
    "        [255, 719]   # bottom left\n",
    "    ]\n",
    "\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "dst = [[350,0],   [930,0],  [350,720],[930,720]]\n",
    "result = fnp.pipeline_for_image2(img, mtx, dist, corners)\n",
    "print(result.shape)\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_video='output_video1.mp4'\n",
    "%time fnp.pipeline_for_video2(mtx, dist, corners, output_video=output_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_video))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the challenge 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dont_run=True\n",
    "if dont_run is False:\n",
    "    input_video='challenge_video.mp4'\n",
    "    output_video=\"out_\"+input_video\n",
    "\n",
    "    %time fnp.pipeline_for_video(mtx, dist, corners, input_video=input_video, output_video=output_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the challenge 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if dont_run is False:\n",
    "    input_video='harder_challenge_video.mp4'\n",
    "    output_video=\"out_\"+input_video\n",
    "\n",
    "    %time fnp.pipeline_for_video(mtx, dist, corners, input_video=input_video, output_video=output_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
